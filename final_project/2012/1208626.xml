<?xml version="1.0" encoding="UTF-8"?>

<rootTag> 
  <Award> 
    <AwardTitle>NRI-Small: Measuring Unconstrained Grasp Forces Using Fingernail Imaging</AwardTitle>  
    <AwardEffectiveDate>08/01/2012</AwardEffectiveDate>  
    <AwardExpirationDate>07/31/2017</AwardExpirationDate>  
    <AwardAmount>917999</AwardAmount>  
    <AwardInstrument> 
      <Value>Standard Grant</Value> 
    </AwardInstrument>  
    <Organization> 
      <Code>05020000</Code>  
      <Directorate> 
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName> 
      </Directorate>  
      <Division> 
        <LongName>Division of Information &amp; Intelligent Systems</LongName> 
      </Division> 
    </Organization>  
    <ProgramOfficer> 
      <SignBlockName>Jie Yang</SignBlockName> 
    </ProgramOfficer>  
    <AbstractNarration>This project develops the technology for unconstrained measurement of human grasp forces. Measurement of multi-fingered grasp forces typically requires a human to grasp an object at predefined sensor locations or to wear instrumented gloves that impede haptic sensations. The objective of this project is to characterize the ability to estimate three-dimensional grasp forces at the fingertips by measuring the color change of the fingernail. This fingernail imaging technique allows the human subject to freely choose where to place the fingers on the object, allowing for completely unconstrained multi-finger grasping. A magnetic levitation device is used to apply a range of 3-D forces to the human fingertip while collecting images of the fingernail. Various image processing techniques are being explored to register the fingernail images to a standard template, and various mathematical models relating pixel intensity to force are being investigated to determine an optimal method. A robotic motion-tracking technique is being implemented to keep the fingers in view of the camera as the hand moves during grasping experiments. The fingernail imaging technique is first validated using constrained grasping experiments, and then applied to unconstrained grasping experiments.&lt;br/&gt;&lt;br/&gt;This research enables a co-robot to detect the individual finger forces of a human partner using a technique that does not interfere with the human's haptic sense. A co-robot trained with the appropriate calibration data could recognize and emulate or adapt to a human partner's grasp forces, measured using only vision. Research efforts are being integrated into the Robotics education and outreach at the University of Utah.</AbstractNarration>  
    <MinAmdLetterDate>07/18/2012</MinAmdLetterDate>  
    <MaxAmdLetterDate>07/18/2012</MaxAmdLetterDate>  
    <ARRAAmount/>  
    <AwardID>1208626</AwardID>  
    <Investigator> 
      <FirstName>John</FirstName>  
      <LastName>Hollerbach</LastName>  
      <EmailAddress>jmh@cs.utah.edu</EmailAddress>  
      <StartDate>07/18/2012</StartDate>  
      <EndDate/>  
      <RoleCode>2</RoleCode> 
    </Investigator>  
    <Investigator> 
      <FirstName>Stephen</FirstName>  
      <LastName>Mascaro</LastName>  
      <EmailAddress>smascaro@mech.utah.edu</EmailAddress>  
      <StartDate>07/18/2012</StartDate>  
      <EndDate/>  
      <RoleCode>1</RoleCode> 
    </Investigator>  
    <Institution> 
      <Name>University of Utah</Name>  
      <CityName>SALT LAKE CITY</CityName>  
      <ZipCode>841128930</ZipCode>  
      <PhoneNumber>8015816903</PhoneNumber>  
      <StreetAddress>75 S 2000 E</StreetAddress>  
      <CountryName>United States</CountryName>  
      <StateName>Utah</StateName>  
      <StateCode>UT</StateCode> 
    </Institution>  
    <ProgramElement>
      <Code>8013</Code>
      <Text>National Robotics Initiative</Text>
    </ProgramElement>
  </Award> 
</rootTag>
