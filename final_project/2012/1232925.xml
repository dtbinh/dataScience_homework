<?xml version="1.0" encoding="UTF-8"?>

<rootTag> 
  <Award> 
    <AwardTitle>Collaborative Research: Motivated Underreporting</AwardTitle>  
    <AwardEffectiveDate>12/30/2011</AwardEffectiveDate>  
    <AwardExpirationDate>09/30/2013</AwardExpirationDate>  
    <AwardAmount>273268</AwardAmount>  
    <AwardInstrument> 
      <Value>Standard Grant</Value> 
    </AwardInstrument>  
    <Organization> 
      <Code>04050000</Code>  
      <Directorate> 
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName> 
      </Directorate>  
      <Division> 
        <LongName>Division of Social and Economic Sciences</LongName> 
      </Division> 
    </Organization>  
    <ProgramOfficer> 
      <SignBlockName>Cheryl L. Eavey</SignBlockName> 
    </ProgramOfficer>  
    <AbstractNarration>This research examines three forms of survey measurement error and investigates the relations among them. The first form of measurement error affects questions designed to identify members of the population eligible for a given survey (for example, persons over 65 years old). Several studies find that members of the eligible population are underreported in screening interviews. Although no survey perfectly covers its target population, surveys aimed at specific subpopulations seem especially prone to undercover that particular population. The second form of measurement error involves filter questions. These are questions that, depending on how they are answered, either lead to additional follow-up questions or to the respondent's skipping out of the follow-up items. Many survey researchers believe that respondents are likely to give false answers to the filter questions in order to avoid the follow-up questions. As a result, many surveys ask the filter questions at the beginning of the questionnaire and administer the follow-up questions later on rather than interleaving the filter and follow-up questions. The final form of measurement error involves conditioning, or time-in-sample, effects. Over the last forty years, many survey researchers have suggested that respondents in ongoing panel surveys report fewer relevant events across waves of the panel survey and across time periods in a diary survey.&lt;br/&gt;&lt;br/&gt;What the three phenomena appear to have in common is underreporting motivated by the desire to reduce the effort needed to complete the questionnaire. But it is not clear whether these forms of error result from something the interviewers do, something the respondents do, or both. The proposed studies use both new experiments and analyze existing data to try to pinpoint the locus of these effects (interviewers versus respondents) and to explore the effectiveness of different methods for reducing these errors. The project will contribute to the improvement of various national statistics that are derived from survey items affected by these problems. The project also will further the training of graduate students and contribute to the professional training of survey researchers at both institutions. The research is supported by the Methodology, Measurement, and Statistics Program and a consortium of federal statistical agencies as part of a joint activity to support research on survey and statistical methodology.</AbstractNarration>  
    <MinAmdLetterDate>04/24/2012</MinAmdLetterDate>  
    <MaxAmdLetterDate>04/24/2012</MaxAmdLetterDate>  
    <ARRAAmount/>  
    <AwardID>1232925</AwardID>  
    <Investigator> 
      <FirstName>Roger</FirstName>  
      <LastName>Tourangeau</LastName>  
      <EmailAddress>RogerTourangeau@Westat.com</EmailAddress>  
      <StartDate>04/24/2012</StartDate>  
      <EndDate/>  
      <RoleCode>1</RoleCode> 
    </Investigator>  
    <Institution> 
      <Name>Westat Inc</Name>  
      <CityName>ROCKVILLE</CityName>  
      <ZipCode>208500319</ZipCode>  
      <PhoneNumber>3012511500</PhoneNumber>  
      <StreetAddress>1650 RESEARCH BLVD</StreetAddress>  
      <CountryName>United States</CountryName>  
      <StateName>Maryland</StateName>  
      <StateCode>MD</StateCode> 
    </Institution>  
    <ProgramElement> 
      <Code>1333</Code>  
      <Text>METHOD, MEASURE &amp; STATS</Text> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>8800</Code>  
      <Text>SCIENCE RESOURCES STATISTICS</Text> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I238</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I239</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I269</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I298</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I308</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I345</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I346</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement> 
      <Code>I402</Code>  
      <Text/> 
    </ProgramElement>  
    <ProgramElement>
      <Code>I420</Code>
      <Text></Text>
    </ProgramElement>
  </Award> 
</rootTag>
