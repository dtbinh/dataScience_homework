<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: Mining and Learning Visual Contexts for Video Scene Understanding</AwardTitle>
    <AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2015</AwardExpirationDate>
    <AwardAmount>428880</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project investigates a fundamental and critical, but largely unexplored issue: automatically identifying visual contexts and discovering visual patterns. Many contemporary approaches that attempt to divide and conquer the video scenes by analyzing the visual objects separately are largely confronted. Exploring visual context has shown its promise for video scene understanding. Discovering visual contexts is a challenging task, due to the content uncertainty in visual data, structure uncertainty in visual contexts, and semantic uncertainty in visual patterns. The goal of this project is to lay the foundation of contextual mining and learning for video scene understanding, by pursuing innovative approaches to discovering collocation visual patterns, to empowering contextual matching of visual patterns, and to facilitating contextual modeling for visual recognition. The research team develops a unified approach to mining visual collocation patterns and learning visual contexts, and to provide methods and tools that facilitate contextual matching and modeling. &lt;br/&gt;&lt;br/&gt;This research significantly advances video scene modeling and understanding, and produces an important enabling technology for a wide range of applications including image/video management and search, intelligent surveillance and security, human-computer interaction, social networks, etc. This research program contributes to education through curriculum development, student involvements, and workshops and tutorials outside the vision community. This project also outreaches to K-12 education, and it provides datasets and software on its website to the community.</AbstractNarration>
    <MinAmdLetterDate>07/24/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>06/10/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1217302</AwardID>
    <Investigator>
      <FirstName>Ying</FirstName>
      <LastName>Wu</LastName>
      <EmailAddress>yingwu@eecs.northwestern.edu</EmailAddress>
      <StartDate>07/24/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Northwestern University</Name>
      <CityName>Evanston</CityName>
      <ZipCode>602013149</ZipCode>
      <PhoneNumber>8474913003</PhoneNumber>
      <StreetAddress>1801 Maple Ave.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
