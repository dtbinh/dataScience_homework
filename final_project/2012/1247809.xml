<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Collaborative Research: Towards Modeling Human Speech Confusions in Noise</AwardTitle>
    <AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2014</AwardExpirationDate>
    <AwardAmount>100000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This EArly-concept Grant for Exploratory Research (EAGER) supports an exploratory study to evaluate model components for prediction of human speech recognition in the presence of noise. Such a model has the potential to predict confusions between fine phonetic distinctions in different levels of background noise and at different speaking rates. The study takes advantage of modern physiological results that indicate that the primary auditory cortex performs spectro-temporal filtering; that is, that there are cells that are sensitive to particular spectro-temporal modulations at each auditory frequency. In this project, perceptual experiments in the presence of both stationary and non-stationary additive noise and at different signal-to-noise ratios for a database of CVC syllables recorded at 2 different speaking rates yield confusion statistics. These statistics are then compared to those resulting from an auditory model enhanced by elements incorporating these spectro-temporal filters. &lt;br/&gt;&lt;br/&gt;Successful results from this study will suggest enhancements to current hearing models and ultimately, after a broader study for which this EAGER is a pilot, advance the understanding of human speech perception. Background noise presents a challenging problem for a variety of speech and hearing devices including hearing aids and automatic speech recognition (ASR) systems. Since normal-hearing human listeners are extremely adept at perceiving speech in noise, this improved understanding of human models could lead to better artificial systems for speech processing. The databases and tools developed for this study will be disseminated to the research community.</AbstractNarration>
    <MinAmdLetterDate>08/08/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>08/08/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1247809</AwardID>
    <Investigator>
      <FirstName>Abeer</FirstName>
      <LastName>Alwan</LastName>
      <EmailAddress>alwan@ee.ucla.edu</EmailAddress>
      <StartDate>08/08/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Jody</FirstName>
      <LastName>Kreiman</LastName>
      <EmailAddress>jkreiman@ucla.edu</EmailAddress>
      <StartDate>08/08/2012</StartDate>
      <EndDate/>
      <RoleCode>2</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Los Angeles</Name>
      <CityName>LOS ANGELES</CityName>
      <ZipCode>900952000</ZipCode>
      <PhoneNumber>3107940102</PhoneNumber>
      <StreetAddress>11000 Kinross Avenue, Suite 211</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
