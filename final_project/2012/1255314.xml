<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Characterizing and Exposing Bias in Social and Mainstream Media</AwardTitle>
    <AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>185000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Nina Amla</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries like search engines can censor or manipulate citizens' access to information. The practices of these intermediaries can create "filter bubbles'', whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately apparent, such as the user's geographic location or past behavior. &lt;br/&gt;&lt;br/&gt;This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media. To study these effects, this project will build a large-scale, distributed monitoring system to discover and view news sources from different geographic regions, and for users with different context. The first portion of the project, which will be to characterize filter bubbles in news media, will involve two separate studies: one for information intermediaries for mainstream news media, and one for social media. The second portion of our project will involve developing and deploying a prototype system that exposes bias in news sources, to provide users with systematic ways to observe and evaluate the extent of bias that may exist in media sources. The last component of our project will investigate how the presenting evidence of bias or information manipulation affects users' perceptions of and attitudes towards bias in both mainstream and social media. To do so, the project will design and instrument user studies through software distribution, recruitment, and laboratory-based studies, where cases of bias or information manipulation are presented to users through different types of interfaces. These studies will highlight instances of bias using different visualizations and interfaces and observe how users' attitudes change depending on whether and how this information is presented.</AbstractNarration>
    <MinAmdLetterDate>08/28/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>08/28/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1255314</AwardID>
    <Investigator>
      <FirstName>Nicholas</FirstName>
      <LastName>Feamster</LastName>
      <EmailAddress>feamster@cc.gatech.edu</EmailAddress>
      <StartDate>08/28/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maryland College Park</Name>
      <CityName>COLLEGE PARK</CityName>
      <ZipCode>207425141</ZipCode>
      <PhoneNumber>3014056269</PhoneNumber>
      <StreetAddress>3112 LEE BLDG</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maryland</StateName>
      <StateCode>MD</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8060</Code>
      <Text>Secure &amp;Trustworthy Cyberspace</Text>
    </ProgramElement>
  </Award>
</rootTag>
