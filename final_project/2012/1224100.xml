<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>TWC: Small: Understanding and Defending Against Crowdsourced Online Identities</AwardTitle>
    <AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2015</AwardExpirationDate>
    <AwardAmount>494743</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Vijayalakshmi Atluri</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Remarkable things can be achieved by harnessing power of the masses. By breaking down tasks and distributing to users, "crowdsourcing" systems can accomplish complex tasks such as translating books or creating 3D photo tours. Unfortunately, the opposite also holds: misuse of these systems creates powerful tools that can compromise the security of online communities, since today's security mechanisms focus on defending against automated scripts and fake accounts, but not real users.&lt;br/&gt;&lt;br/&gt;In a malicious crowdsourcing system, customers initiate campaigns, and workers are paid for tasks such as creating Facebook accounts, posting fake Yelp reviews, or starting rumors on Twitter, with results indistinguishable from those of normal users. This type of malicious activity is called crowdturfing, because of its similarity to both crowd-sourcing systems and "astroturfing." The PIs have already found example sites today, and early measurements show some that generate over $1Million in annual revenue, while growing exponentially in users and revenue.&lt;br/&gt;&lt;br/&gt;This project studies crowdturfing systems in detail via measurements and experiments, and use those results to develop robust defenses against them. Measurements and interviews will be used to study their support structure and incentives; develop endhost-based techniques to mark their results and economic solutions that reduce incentives for customers and workers; and build effective detection systems that identify crowdturfing in different domains using per-user behavioral models.&lt;br/&gt;&lt;br/&gt;This work can change the way we view security in online communities, and its results can guide the deployment of new protection mechanisms that target crowdsourced fake user accounts and activities.</AbstractNarration>
    <MinAmdLetterDate>08/28/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>08/28/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1224100</AwardID>
    <Investigator>
      <FirstName>Ben</FirstName>
      <LastName>Zhao</LastName>
      <EmailAddress>ravenben@cs.ucsb.edu</EmailAddress>
      <StartDate>08/28/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Haitao</FirstName>
      <LastName>Zheng</LastName>
      <EmailAddress>htzheng@cs.ucsb.edu</EmailAddress>
      <StartDate>08/28/2012</StartDate>
      <EndDate/>
      <RoleCode>2</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Santa Barbara</Name>
      <CityName>SANTA BARBARA</CityName>
      <ZipCode>931062050</ZipCode>
      <PhoneNumber>8058934188</PhoneNumber>
      <StreetAddress>Office of Research</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8060</Code>
      <Text>Secure &amp;Trustworthy Cyberspace</Text>
    </ProgramElement>
  </Award>
</rootTag>
