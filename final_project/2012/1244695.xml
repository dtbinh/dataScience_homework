<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Automatically Annotated Repository of Digital Video and Audio Resources Community (AARDVARC)</AwardTitle>
    <AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2015</AwardExpirationDate>
    <AwardAmount>86253</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Behavioral and Cognitive Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William J. Badecker</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Audio and video data from understudied languages is useful to linguists, anthropologists, educators, and computer scientists interested in visual action extraction, speech technology or software localization. Terabytes of such data exist, having been collected in large amounts by documentary linguists since the advent of easy digital recording via handheld devices. As records of vanishing languages and cultures, video and audio records are far richer and more captivating than paper records, but they need to be indexed and transcribed so that they reach their full potential as research tools. The current project, AARDVARC (Automatically Annotated Repository of Digital Audio and Video Resources Community) will address the problem of untranscribed, and therefore unavailable, documentation of understudied languages by building an interdisciplinary community of linguists, anthropologists, and computer scientists to share knowledge and collaborate on the specification of a repository and suite of tools to facilitate transcription. It will provide for two workshops and a symposium to design a "take one leave one" repository and to explore recent advances in speech and video processing that will allow anthropologists and linguists to break the 'transcription bottleneck' for language data. Even partial automation will greatly facilitate the work of the analyst and dramatically increase the amount of transcribed audio and video available to researchers in multiple disciplines.</AbstractNarration>
    <MinAmdLetterDate>09/23/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>09/23/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1244695</AwardID>
    <Investigator>
      <FirstName>Douglas</FirstName>
      <LastName>Whalen</LastName>
      <EmailAddress>dwhalen@gc.cuny.edu</EmailAddress>
      <StartDate>09/23/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>CUNY Graduate School University Center</Name>
      <CityName>New York</CityName>
      <ZipCode>100164309</ZipCode>
      <PhoneNumber>2128177523</PhoneNumber>
      <StreetAddress>365 Fifth Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8068</Code>
      <Text>Data Infrastructure</Text>
    </ProgramElement>
  </Award>
</rootTag>
