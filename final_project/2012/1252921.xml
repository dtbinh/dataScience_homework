<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Data Association and Exploitation for Large Scale 3D Modeling from Visual Imagery</AwardTitle>
    <AwardEffectiveDate>09/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2014</AwardExpirationDate>
    <AwardAmount>296480</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project addresses three main challenges in large scale 3D modeling from photocollections: 1) efficient and complete data linkage, 2) Inference and modeling of scene and user dynamics, and 3) development of data adaptive algorithms. These challenges are tackled within the framework of data association and exploitation. The benefits of such an approach are two fold. First, through enhanced data association, the approach increases the scope of 3D models due to more complete data linkage. Second, through the development of algorithms that are not only robust against (and mitigate) input data variability, but also explicitly designed to exploit this diversity and data richness, the approach increases fidelity of 3D models. The specific data association tasks of this project include: location recognition, view planning for 3D reconstruction, online learning for feature matching, and modeling under scene symmetries. The specific data exploitation tasks of this project include: model update and archiving, native resolution modeling, high resolution dynamic texture estimation, and exploring and leveraging user behavior. &lt;br/&gt;&lt;br/&gt;This work enables the broad deployment of applications where fully automated scene modeling expands from determining structure properties to encompass the modeling of observable behavioral patterns both in the scene and in the user controlled image capture process. The developed technologies have a wide range of applications, from virtual tourism, to cultural heritage preservation, to disaster response.</AbstractNarration>
    <MinAmdLetterDate>08/31/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>08/31/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1252921</AwardID>
    <Investigator>
      <FirstName>Jan-Michael</FirstName>
      <LastName>Frahm</LastName>
      <EmailAddress>jmf@cs.unc.edu</EmailAddress>
      <StartDate>08/31/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Enrique</FirstName>
      <LastName>Dunn</LastName>
      <EmailAddress>dunn@cs.unc.edu</EmailAddress>
      <StartDate>08/31/2012</StartDate>
      <EndDate/>
      <RoleCode>2</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of North Carolina at Chapel Hill</Name>
      <CityName>CHAPEL HILL</CityName>
      <ZipCode>275991350</ZipCode>
      <PhoneNumber>9199663411</PhoneNumber>
      <StreetAddress>104 AIRPORT DR STE 2200</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
    <ProgramElement>
      <Code>L582</Code>
      <Text></Text>
    </ProgramElement>
  </Award>
</rootTag>
