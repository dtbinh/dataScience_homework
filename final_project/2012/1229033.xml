<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RUI: Phonetic Convergence in Spoken Communication</AwardTitle>
    <AwardEffectiveDate>08/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2015</AwardExpirationDate>
    <AwardAmount>400098</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Behavioral and Cognitive Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Betty H. Tuller</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Spoken communication works so well that its efficacy is taken for granted. Two complete strangers who meet for the first time and speak the same language can converse with relative ease from the moment of introduction. How is this feat accomplished? The fact that talkers share a language with similar vocabulary and grammatical rules is only part of the answer. Because of the enormous variability in phonetic forms used by speakers of the same language, how an individual speaks is as important as what he or she says. When talkers converse, they often adopt some of the phonetic attributes of their conversational partners, a process termed "phonetic convergence." On other occasions, talkers diverge from each other or show little change in their phonetic repertoire. Moreover, some talkers are more adept than others at shedding an accent or adopting the accent of a foreign language. The current project aims to further our understanding of these interactive effects by investigating the relationship between individual perceptual and learning abilities and acoustic-phonetic variability across both nonsocial and conversational settings. Delineating how individual speakers adjust to each other is crucial to understanding communication in interactive, multi-talker settings.&lt;br/&gt;&lt;br/&gt;This project has the potential for broad impact across many domains that rely on social interaction of talkers, such as learning a second language, remediation of speech pathologies, and human-computer interaction through the medium of speech. The award is for Research in Undergraduate Institutions and incorporates undergraduate student participation at all levels of the work, from design and data collection to reporting and presentation of results. The recordings and transcription data will also be made available online to other qualified researchers interested in studying the phenomena of conversational interaction via the Linguistics Data Consortium.</AbstractNarration>
    <MinAmdLetterDate>07/26/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>07/26/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1229033</AwardID>
    <Investigator>
      <FirstName>Jennifer</FirstName>
      <LastName>Pardo</LastName>
      <EmailAddress>pardoj@mail.montclair.edu</EmailAddress>
      <StartDate>07/26/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Montclair State University</Name>
      <CityName>Montclair</CityName>
      <ZipCode>070431624</ZipCode>
      <PhoneNumber>9736556923</PhoneNumber>
      <StreetAddress>1 Normal Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
  </Award>
</rootTag>
