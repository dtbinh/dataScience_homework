<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Sensory Integration and Sensorimotor Transformations for Dexterous Manipulation</AwardTitle>
    <AwardEffectiveDate>03/15/2012</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2015</AwardExpirationDate>
    <AwardAmount>209505</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Directorate for Social, Behavioral &amp; Economic Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Behavioral and Cognitive Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Betty H. Tuller</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The ability to grasp and manipulate objects is an extremely complex motor behavior. When grasping an object such as a cup, people often vary their finger placements and the forces exerted by the fingers in order to ensure that the goal is attained (in this case, lifting the cup without spilling its contents). How humans do this so efficiently is not known, in part because previous research constrained subjects to place their fingers at pre-specified locations on the objects. This has led to a major gap in our understanding of how these complex motor behaviors are learned, planned, and executed. To address this gap, the proposed studies will investigate how subjects grasp and manipulate objects in tasks that allow them to choose their finger placements and applied forces and, importantly, to adjust the interaction between the two. Another function of grasping is to develop a representation of an object's weight and the distribution of weight within the object. How subjects develop this representation and refine their actions will be examined by studying the interaction between information extracted by grasping and memories of past manipulations of the object. The hypothesis that fingertip placement and forces are learned independently from each other will be tested by manipulating visual feedback of fingertip placement, varying visual shape and density cues, and through object rotation tasks that create a discrepancy between visual cues and memories of the same object from prior manipulations.&lt;br/&gt;&lt;br/&gt;The proposed studies represent a major paradigm shift in the research on grasping by opening new and fundamental questions about how the brain learns to control the hand. Thus, the results of this work may inform the design of more dexterous robotic manipulators, brain-machine interfaces, and neuroprosthetic hands.</AbstractNarration>
    <MinAmdLetterDate>02/13/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>07/30/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1153034</AwardID>
    <Investigator>
      <FirstName>Marco</FirstName>
      <LastName>Santello</LastName>
      <EmailAddress>marco.santello@asu.edu</EmailAddress>
      <StartDate>02/13/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Arizona State University</Name>
      <CityName>TEMPE</CityName>
      <ZipCode>852816011</ZipCode>
      <PhoneNumber>4809655479</PhoneNumber>
      <StreetAddress>ORSPA</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Arizona</StateName>
      <StateCode>AZ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
  </Award>
</rootTag>
