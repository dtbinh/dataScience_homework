<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Visual Saliency with Discriminancy, Sparsity and Connectivity</AwardTitle>
    <AwardEffectiveDate>01/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2013</AwardExpirationDate>
    <AwardAmount>135742</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project explores new directions to solving top-down modulated visual saliency maps with three basic principles: discriminancy, sparsity and connectivity. The research identifies key factors for advancing the state-of-the-art and presents a novel latent variable model, which extends the classical conditional random field with an embedded layer of latent variables to exploit the sparsity nature of features for saliency maps. This sparse latent variable conditional random filed model can be considered as a joint optimization of group sparse coding and conditional random field, which can be solved with an efficient stochastic gradient descent algorithm. Unlike bottom-up saliency, this model facilities high-level visual recognition tasks by learning sparse image structures from objects of interest. The key intellectual contributions of this project are a novel formulation that considers all three important properties for visual saliency in a unified framework, and an efficient learning algorithm to estimate the model parameters. &lt;br/&gt;&lt;br/&gt;With the developed techniques, the search regions of these vision tasks can be constrained and thereby reduce the computational complexity and enhancing robustness. Effective top-down modulated visual saliency algorithms have broad applications including object detection, object recognition, visual tracking, scene analysis, image compression, surveillance, and robotics. It also provides a crucial tool for studying and analyzing fixations of eye movements in cognitive science. The research results including code and data are made public on the project web site.</AbstractNarration>
    <MinAmdLetterDate>08/26/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/26/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1152576</AwardID>
    <Investigator>
      <FirstName>Ming-Hsuan</FirstName>
      <LastName>Yang</LastName>
      <EmailAddress>mhyang@ucmerced.edu</EmailAddress>
      <StartDate>08/26/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California - Merced</Name>
      <CityName>Merced</CityName>
      <ZipCode>953435001</ZipCode>
      <PhoneNumber>2092284318</PhoneNumber>
      <StreetAddress>5200 North Lake Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7364</Code>
      <Text>INFO INTEGRATION &amp; INFORMATICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
