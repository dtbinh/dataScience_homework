<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Computer Architectures and Algorithms for Adaptive Human Computer Interfaces</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>150000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Todd Leen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The ease of use of a human computer interface depends critically on the latency of the system and its ability to adapt to the environment. Differences in lighting, visual appearance and user behavior can significantly alter the input data. Furthermore, the reaction time must be less than 100 milliseconds to appear instantaneous to the user. Achieving high accuracy demands a system that adapts to these changing characteristics while processing a significant amount of data in a short amount of time.&lt;br/&gt;&lt;br/&gt;We propose a computer architecture for adaptive real-time signal processing systems that combines a general purpose processor with custom hardware. The custom hardware performs the low-level, high-throughput signal processing on the raw signals and feeds them to the processor which performs the high level signal processing and decision making. The processor also executes machine learning algorithms that change the parameters of the low-level processing to adapt them to the current statistical properties of the data.&lt;br/&gt;&lt;br/&gt;This project will develop a human-computer interface based on audio and video sensors that allows a user to interact with the computer through gestures and voice alone. This requires research advances in computer architecture, embedded systems, signal processing, machine learning and human-computer interaction. The major research challenge is in the integration of knowledge from the different areas to create a functional system. This system will serve as a prototype for novel human computer interactions and will be a foundation for future collaboration between the different fields.</AbstractNarration>
    <MinAmdLetterDate>07/22/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/22/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1143995</AwardID>
    <Investigator>
      <FirstName>Ryan</FirstName>
      <LastName>Kastner</LastName>
      <EmailAddress>kastner@ucsd.edu</EmailAddress>
      <StartDate>07/22/2011</StartDate>
      <EndDate/>
      <RoleCode>2</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Yoav</FirstName>
      <LastName>Freund</LastName>
      <EmailAddress>yfreund@ucsd.edu</EmailAddress>
      <StartDate>07/22/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-San Diego</Name>
      <CityName>La Jolla</CityName>
      <ZipCode>920930934</ZipCode>
      <PhoneNumber>8585344896</PhoneNumber>
      <StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
