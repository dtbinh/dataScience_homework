<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative: Gesture Recognition Challenge</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>55920</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07010000</Code>
      <Directorate>
        <LongName>Directorate for Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Electrical, Communications and Cyber Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Paul Werbos</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The objective of this research is both to advance the field of video data processing (more particularly gesture recognition) and to illustrate the power of deep learning architectures and transfer learning. The approach is to organize a challenge culminating in a life evaluation at the site of a conference.&lt;br/&gt;Intellectual merit: Much of the recent research in Adaptive and Intelligent Systems (AIS) has sacrificed the grand goal of designing systems ever approaching human intelligence for solving data mining tasks of practical interest with more immediate reward. This project gives an opportunity to deep learning architectures inspired by neural networks to demonstrate their ability to address more complex problems requiring to transfer knowledge from task to task (transfer learning), leveraging the availability of video data not directly related to the target task of gesture recognition. The participants will also be involved in a data exchange to grow an unprecedented large and diverse database of gestures. &lt;br/&gt;Broader Impact: Challenges have proved to be a great stimulus of research. For a long lasting impact, the challenge platform and the data and software repositories will remain open beyond the term of the NSF funded project. The educational components of the project include engaging students in the contest, providing material directly usable in teaching curricula, and demonstrating gesture recognition to high school students to expose them to computer vision research and sign language communication. Our connections with the deaf community will allow us to gear the product of this research to advance assistive technology.</AbstractNarration>
    <MinAmdLetterDate>07/21/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/13/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1128296</AwardID>
    <Investigator>
      <FirstName>Vassilis</FirstName>
      <LastName>Athitsos</LastName>
      <EmailAddress>athitsos@uta.edu</EmailAddress>
      <StartDate>07/21/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Arlington</Name>
      <CityName>Arlington</CityName>
      <ZipCode>760199000</ZipCode>
      <PhoneNumber>8172722105</PhoneNumber>
      <StreetAddress>1 UNIVERSITY OF TEXAS AT</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7607</Code>
      <Text>ENERGY,POWER,ADAPTIVE SYS</Text>
    </ProgramElement>
  </Award>
</rootTag>
