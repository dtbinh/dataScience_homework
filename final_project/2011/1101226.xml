<?xml version="1.0" encoding="UTF-8"?>

<rootTag> 
  <Award> 
    <AwardTitle>ICES: Small: Manipulation of Learning Heuristics in Strategic Interaction</AwardTitle>  
    <AwardEffectiveDate>07/01/2011</AwardEffectiveDate>  
    <AwardExpirationDate>06/30/2014</AwardExpirationDate>  
    <AwardAmount>188532</AwardAmount>  
    <AwardInstrument> 
      <Value>Standard Grant</Value> 
    </AwardInstrument>  
    <Organization> 
      <Code>05010000</Code>  
      <Directorate> 
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName> 
      </Directorate>  
      <Division> 
        <LongName>Division of Computing and Communication Foundations</LongName> 
      </Division> 
    </Organization>  
    <ProgramOfficer> 
      <SignBlockName>Balasubramanian Kalyanasundaram</SignBlockName> 
    </ProgramOfficer>  
    <AbstractNarration>This project analyzes strategic manipulation of learning players in repeated games. People are not born with optimal strategies, but instead learn to interact in markets and other social situations. Increasingly, humans interact with computerized agents who may be programmed to use some adaptive learning heuristic. Especially when economic success is at stake, resources may be invested to manipulate learning players. First, the Principle Investigator (PI) seeks to find simple adaptive heuristics that are essentially unbeatable by any opponent in generic and economically relevant classes of games. Second, the PI seeks to discover simple adaptive heuristics whose long run outcome can not be manipulated by sophisticated opponents. Such heuristics are of interest to robustly implement outcomes in mechanisms with learning players. Third, the PI will investigate the existence of simple adaptive heuristics whose long run outcome is not only close to Nash equilibrium but which can also not be manipulated by sophisticated opponents in generic and economically relevant classes of games. Prior work on learning in games focuses on simple heuristics that lead in all games to Nash equilibrium. The objective is to settle the important open question whether such learning heuristics themselves can be robust to strategic manipulation. Finally, the PI aims to find dynamically optimal strategies against well-known adaptive heuristics such as myopic best reply, fictitious play, reinforcement learning, imitation, trail &amp; error learning, and regret matching in generic and economically relevant classes of games.&lt;br/&gt;&lt;br/&gt;The findings developed in this project are not only relevant for the theory of learning in games in economics but they are foremost relevant for the understanding of real-life strategic interaction and the design of interacting learning machines. In reality, players almost always have to learn how to interact and are almost always heterogeneous with respect to knowledge, strategic sophistication and learning abilities. This becomes obvious for instance in the increasing interaction of humans with machines such as calling robots and automated trading. Especially for automated trading in financial markets, one expects simple learning players to be manipulated by other more sophisticated players if the latter can achieve a strategic advantage. The results of this project are expected to influence the design of interacting learning machines robust to manipulation in many environments.</AbstractNarration>  
    <MinAmdLetterDate>06/16/2011</MinAmdLetterDate>  
    <MaxAmdLetterDate>06/16/2011</MaxAmdLetterDate>  
    <ARRAAmount/>  
    <AwardID>1101226</AwardID>  
    <Investigator> 
      <FirstName>Burkhard</FirstName>  
      <LastName>Schipper</LastName>  
      <EmailAddress>bcschipper@ucdavis.edu</EmailAddress>  
      <StartDate>06/16/2011</StartDate>  
      <EndDate/>  
      <RoleCode>1</RoleCode> 
    </Investigator>  
    <Institution> 
      <Name>University of California-Davis</Name>  
      <CityName>Davis</CityName>  
      <ZipCode>956180000</ZipCode>  
      <PhoneNumber>5307547700</PhoneNumber>  
      <StreetAddress>OR/Sponsored Programs</StreetAddress>  
      <CountryName>United States</CountryName>  
      <StateName>California</StateName>  
      <StateCode>CA</StateCode> 
    </Institution>  
    <ProgramElement>
      <Code>8052</Code>
      <Text>Inter Com Sci Econ Soc S (ICE)</Text>
    </ProgramElement>
  </Award> 
</rootTag>
