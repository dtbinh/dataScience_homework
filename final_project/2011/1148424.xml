<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: SI2-SSI: A Comprehensive Performance Tuning Framework for the MPI Stack</AwardTitle>
    <AwardEffectiveDate>06/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2015</AwardExpirationDate>
    <AwardAmount>449995</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05090000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Advanced CyberInfrastructure</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Daniel Katz</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The Message Passing Interface (MPI) is a very widely used parallel programming model on modern High-End Computing (HEC) systems. Many performance aspects of MPI libraries, such as latency, bandwidth, scalability, memory footprint, cache pollution, overlap of computation and communication etc. are highly dependent on system configuration and application requirements. Additionally, modern clusters are changing rapidly with the growth of multi-core processors and commodity networking technologies such as InfiniBand and 10GigE/iWARP. They are becoming diverse and heterogeneous with varying number of processor cores, processor speed, memory speed, multi-generation network adapters/switches, I/O interface technologies, and accelerators (GPGPUs), etc. Typically, any MPI library deals with the above kind of diversity in platforms and sensitivity of applications by employing various runtime parameters. These parameters are tuned during its release, or by&lt;br/&gt;system administrators, or by end-users. These default parameters may or may not be optimal for all system configurations and applications.&lt;br/&gt;&lt;br/&gt;The MPI library of a typical proprietary system goes through heavy performance tuning for a range of applications. Since commodity clusters provide greater flexibility in their configurations (processor, memory and network), it is very hard to achieve optimal tuning using released version of any MPI library, with its default settings. This leads to the following broad challenge: "Can a comprehensive performance tuning framework be designed for MPI library so that the next generation InfiniBand, 10GigE/iWARP and RoCE clusters and applications will be able to extract `bare-metal' performance and maximum scalability?" The investigators, involving computer&lt;br/&gt;scientists from The Ohio State University (OSU) and Ohio Supercomputer Center (OSC) as well as computational scientists from the Texas Advanced Computing Center (TACC) and San Diego Supercomputer Center (SDSC), University of California San Diego (UCSD), will be addressing the above challenge with innovative solutions.&lt;br/&gt;&lt;br/&gt;The investigators will specifically address the following challenges: 1) Can a set of static tools be designed to optimize performance of an MPI library during installation time? 2) Can a set of dynamic tools with low overhead be designed to optimize performance on a per-user and per-application basis during production runs? 3) How to incorporate the proposed performance tuning framework with the upcoming MPIT interface? 4) How to configure MPI libraries on a given system to deliver different optimizations to a set of driving applications? and 5) What kind of benefits (in terms of performance, scalability, memory efficiency and reduction in cache pollution) can be achieved by the proposed tuning framework? The research will be driven by a set of applications from established NSF computational science researchers running large scale simulations on the TACC Ranger and other systems at OSC, SDSC and OSU. The proposed designs will be integrated into the open-source MVAPICH2 library.</AbstractNarration>
    <MinAmdLetterDate>06/04/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>06/04/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1148424</AwardID>
    <Investigator>
      <FirstName>Tommy</FirstName>
      <LastName>Minyard</LastName>
      <EmailAddress>minyard@tacc.utexas.edu</EmailAddress>
      <StartDate>06/04/2012</StartDate>
      <EndDate/>
      <RoleCode>2</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>William</FirstName>
      <LastName>Barth</LastName>
      <EmailAddress>bbarth@tacc.utexas.edu</EmailAddress>
      <StartDate>06/04/2012</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8004</Code>
      <Text>Software Institutes</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramElement>
  </Award>
</rootTag>
