<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CGV: EAGER: Simulation-Based Manipulation Capture for Dexterous Character Animation</AwardTitle>
    <AwardEffectiveDate>08/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2013</AwardExpirationDate>
    <AwardAmount>81000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Lawrence Rosenblum</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Through our hands, we communicate, care for ourselves and others, and use tools to affect our world. However, our understanding of how we control our hands to accomplish such feats is still in its infancy. Dexterous manipulation is especially challenging to study, as even "simple" manipulation tasks are complex in their details. The task of lifting a wrench into the hand, for example, can be decomposed into five separate actions, each of which may require a specialized control strategy. It is important to study human examples of such activities; through understanding human expertise we can reach practical outcomes such as physically intelligent animated characters for training and remote communication, robots capable of unprecedented dexterity, and prosthetic designs that far exceed the current state of the art in their elegance and functionality.&lt;br/&gt;&lt;br/&gt;The key hurdle in making a significant advance in these areas is the difficulty of capturing human manipulation in a form that facilitates analysis and study. The rapid sequence of contact events, the hand's large number of degrees of freedom, and close contact between the hand and object all contribute to creating an impossible capture task using traditional methods. The investigators are developing an alternative: simulation motion capture, where a user interacts with and guides a running simulation. Through this innovative approach, details such as contact timing, contact area, and contact forces are made available for the first time for general manipulation tasks. Key innovations include a fast simulation system for a deformable human hand (or full body) and novel techniques to control such a high degree of freedom simulation with intent and precision. In parallel, the investigators create a database of manipulation tasks, study new languages for action segmentation and control law development, develop robust autonomous controllers for grasping and manipulation, and study novel classifiers for recognition of affordances.</AbstractNarration>
    <MinAmdLetterDate>08/06/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/06/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1145640</AwardID>
    <Investigator>
      <FirstName>Nancy</FirstName>
      <LastName>Pollard</LastName>
      <EmailAddress>nsp@cs.cmu.edu</EmailAddress>
      <StartDate>08/06/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7453</Code>
      <Text>GRAPHICS &amp; VISUALIZATION</Text>
    </ProgramElement>
  </Award>
</rootTag>
