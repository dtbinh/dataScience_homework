<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: IIS: RI: Learning in Continuous and High Dimensional Action Spaces</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>149996</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Todd Leen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The proposed research is in the general area of "planning under uncertainty." This topic addresses the problem of choosing good actions in situations where actions do not have deterministic outcomes. Applications for this general framework include but are not limited to robotic control, medical decision making, and business optimization. The overarching mathematical framework for this problem is that of decision theory or Markov decision processes, topics that are studied in a wide range of fields, including engineering, economics, operations research and, more recently, artificial intelligence. &lt;br/&gt;&lt;br/&gt;Recent technical efforts in this area have sought to address large problems by combining successful statistical and machine learning techniques with decision-theoretic reasoning. The underlying insight behind these efforts is that machine learning can generalize across similar states of the world, thereby allowing algorithms to propose good actions for new states of the world without explicitly considering every possible state or outcome, as was required by classical approaches.&lt;br/&gt;&lt;br/&gt;The combination of classical decision theoretic methods and machine learning has shown great promise for large state spaces, but one aspect that has been under-explored is large action spaces. Large action spaces arise naturally from a fine discretization of a continuous action space or from a large set of discrete choices, such as assignments of firefighters to regions on a map. One way to address the general challenge would be to group actions into sets and use machine learning methods to predict which set is preferred. By doing this multiple times over carefully arranged partitions of the action space, it should possible to achieve an exponential reduction in the effort required to select the best action.&lt;br/&gt;&lt;br/&gt;Potential applications of this research include robotic control, power grid management, and forest/fire management strategies.</AbstractNarration>
    <MinAmdLetterDate>08/05/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/05/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1147641</AwardID>
    <Investigator>
      <FirstName>Ronald</FirstName>
      <LastName>Parr</LastName>
      <EmailAddress>parr@cs.duke.edu</EmailAddress>
      <StartDate>08/05/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Duke University</Name>
      <CityName>Durham</CityName>
      <ZipCode>277054010</ZipCode>
      <PhoneNumber>9196843030</PhoneNumber>
      <StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
