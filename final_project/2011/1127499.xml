<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase II: Plug and Play Characters for 3D Virtual Environments</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>0</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate for Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Industrial Innovation and Partnerships</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Errol B. Arkilic</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Innovation Research (SBIR) Phase II project will complete the development of reusable, self-encapsulated animated characters for use in 3D virtual environments. 3D characters are difficult to develop because of the inflexibility of current motion representations. Presently animations are compiled into characters using a static data structure. This makes the addition of new animations an off-line, time-consuming process. Using extensive motion annotation, our technology allows applications to link together animations at run-time. The end-product objective is a network of 3D mobile applications that run on multitouch-enabled devices like smart phones. The technology enables 1) transfer of characters within a growing network of applications (i.e., 'plug and play' characters), 2) user selection of animations to use in each application, and 3) character control through a novel multitouch-based interface. Intellectual merits involve creation of a character authoring and control interface, and analysis of alternative, flexible representations of character animation at the semantic level. &lt;br/&gt;&lt;br/&gt;This project will have broader impact in three areas. First, multitouch is a new interactive paradigm that will become ubiquitous through the proliferation of smart phones and tablets. This project will investigate multitouch schemes for intuitive control of complex, articulated models such as 3D humanoid figures. Second, this project will advance our understanding of semantic categories for human motion. Such labels are important for motion synthesis and motion recognition. Third, this project will develop methods for building virtual environments incrementally. Virtual environments are used widely in entertainment, training simulations, virtual worlds, and other 3D applications. The company will develop technology for adding new assets in a scalable manner.</AbstractNarration>
    <MinAmdLetterDate>09/01/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>01/24/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1127499</AwardID>
    <Investigator>
      <FirstName>Okan</FirstName>
      <LastName>Arikan</LastName>
      <EmailAddress>okarikan@gmail.com</EmailAddress>
      <StartDate>09/01/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>Animeeple Inc.</Name>
      <CityName>Mountain View</CityName>
      <ZipCode>940401088</ZipCode>
      <PhoneNumber>6504175020</PhoneNumber>
      <StreetAddress>146 Montelena Ct.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>5373</Code>
      <Text>SMALL BUSINESS PHASE II</Text>
    </ProgramElement>
  </Award>
</rootTag>
