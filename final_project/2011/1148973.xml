<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Noise and strong analog error-correcting codes in neural computation</AwardTitle>
    <AwardEffectiveDate>10/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2013</AwardExpirationDate>
    <AwardAmount>175000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Directorate for Computer &amp; Information Science &amp; Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Kenneth C. Whang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project aims to uncover the existence of a qualitatively better class of analog error-correcting codes than previously known in the brain, show how such codes can be used and decoded, and develop the theory for quantifying the performance of such codes. &lt;br/&gt;&lt;br/&gt;Information theory was introduced into neuroscience relatively early, and the theory of efficient (source) coding has been widely embraced in the sensory neurosciences. However, the second branch of information theory, which deals with the maximally parsimonious addition of redundancy to recover signal from noise, has curiously not made inroads in neuroscience. Shannon's channel coding theorem revealed the existence of codes that make possible error correction at efficiencies previously thought impossible.&lt;br/&gt;&lt;br/&gt;The investigator's central hypothesis is that the brain routinely employs such error correcting codes and the machinery required to decode and work with them. The hypothesis is motivated by a recent analysis of the grid cell code for animal location by the investigator and colleagues, showing it has unprecedented error-correction properties compared to known population codes in the brain (Sreenivasan &amp; Fiete, 2011). The investigator proposes to: 1) Develop definitions and constraints for analog neural codes, to apply the channel coding framework to neural codes and thus characterize their "goodness" on error-correction. 2) Identify high-level coding properties that enable strong error-correction, and search for these properties in observed but poorly understood neural codes. At the same time, explore strong theoretical error-correcting codes that the brain may plausibly implement. 3) Model plausible neural mechanisms for decoding such codes. Decoding is inference, so this question can be more generally thought of as exploring neural mechanisms for hierarchical inference. &lt;br/&gt;&lt;br/&gt;This project is computational and theoretical, and also involves close collaboration with neurophysiologists, to apply quantification techniques to neural data and work with experiments to inform the theories and test predictions.</AbstractNarration>
    <MinAmdLetterDate>08/31/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/31/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1148973</AwardID>
    <Investigator>
      <FirstName>Ila</FirstName>
      <LastName>Fiete</LastName>
      <EmailAddress>ilafiete@mail.clm.utexas.edu</EmailAddress>
      <StartDate>08/31/2011</StartDate>
      <EndDate/>
      <RoleCode>1</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
  </Award>
</rootTag>
